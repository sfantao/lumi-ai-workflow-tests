FROM registry.suse.com/bci/bci-base:15.7-5.8.33

#
# Disable BCI repros
#

RUN set -eux ; \
  sed -i 's#enabled=1#enabled=0#g' /etc/zypp/repos.d/SLE_BCI.repo 

RUN set -eux ; \
  zypper -n addrepo https://download.opensuse.org/distribution/leap/16.0/repo/oss myrepo3 ; \
  echo 'gpgcheck=0' >> /etc/zypp/repos.d/myrepo3.repo ; \
  true

#   zypper -n addrepo https://download.opensuse.org/repositories/devel:/languages:/perl/SLE_15_SP6 myrepo4 ; \
#   echo 'gpgcheck=0' >> /etc/zypp/repos.d/myrepo4.repo
  
RUN set -eux ; \
  sed -i 's#gpgcheck=1#gpgcheck=0#g' /etc/zypp/repos.d/*.repo


#
# Install build dependencies
#

RUN set -eux; \
  zypper -n refresh ; \
  zypper --no-gpg-checks -n install -y --force-resolution \
    git cmake gcc15 gcc15-c++ gcc15-fortran zlib-devel numactl awk patch tar autoconf automake libtool libjson-c-devel graphviz ncurses-devel nano which libjansson4 libnl3-200; \
  zypper cc -a

# #
# # Cray info
# #
# ENV CPE_VERSION "cscs"
# ENV LIBFABRIC_VERSION "1.22.0"
# ENV LIBFABRIC_PATH /opt/cray/libfabric/$LIBFABRIC_VERSION
# ENV MPICH_PATH "/user-environment/linux-zen4/cray-mpich-8.1.32-cxtmuwnixgrhmmbaioodhybfeh3ahzpo"
# ENV LD_LIBRARY_PATH $LIBFABRIC_PATH/lib64:$MPICH_PATH/lib

# ARG SERVER_PORT
# ENV DOWNLOAD_CRAY_DEPS '\
#   mkdir /h; \
#   cd /h ; \
#   curl -LO http://localhost:$SERVER_PORT/index ; \
#   for i in $(cat index) ; do \
#     curl -LO http://localhost:$SERVER_PORT/$i ; \
#   done'

# ENV REMOVE_CRAY_DEPS 'rm -rf /h /user-environment /opt/cray /usr/lib64/libcxi.so*'

# RUN set -eux ; \
#   bash -eux -o pipefail -c "$DOWNLOAD_CRAY_DEPS" ; \
#   ls /h ; \
#   cat /h/index ; \
#   bash -eux -o pipefail -c "$REMOVE_CRAY_DEPS" ; \
#   ls -la /

# ENV ROCM_RPM https://repo.radeon.com/amdgpu/6.3.4/sle/15.6/main/x86_64/amdgpu-install-6.3.60304-2125197.noarch.rpm
# ENV ROCM_RELEASE 6.3.4

# RUN set -eux ; \
#   zypper --no-gpg-checks -n install $ROCM_RPM

# RUN set -eux ; \
#   sed -i 's#gpgcheck=1#gpgcheck=0#g' /etc/zypp/repos.d/*.repo

# RUN set -eux ; \
#   zypper refresh ; \
#   amdgpu-install -y --no-dkms --usecase=rocm --rocmrelease=$ROCM_RELEASE ; \
#   zypper cc -a

# RUN set -eux ; \
#   zypper --no-gpg-checks -n install -y --force miopen-hip-gfx942kdb

# RUN set -eux ; \
#   zypper --no-gpg-checks -n install -y --force omniperf omnitrace
  
# #
# # ROCm environment
# #
# ENV ROCM_PATH /opt/rocm-$ROCM_RELEASE
# ENV PATH $ROCM_PATH/bin:$ROCM_PATH/llvm/bin:$PATH
# ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:$ROCM_PATH/lib

# #
# # Mark RCCL as non-debug - this can me overriden by RCCL debug build. 
# #
# ENV RCCL_DEBUG 0

# RUN set -eux ; \
#   bash -eux -o pipefail -c "$DOWNLOAD_CRAY_DEPS" ; \
#   cd $ROCM_PATH/bin ; \
#   for i in rocm_agent_enumerator rocminfo ; do \
#     rm -rf $i ; \
#     cp /h/$i . ; \
#     chmod +x $i ; \
#   done ; \
#   bash -eux -o pipefail -c "$REMOVE_CRAY_DEPS"

# RUN set -eux ; \
#   bash -eux -o pipefail -c "$DOWNLOAD_CRAY_DEPS" ; \
#   cd $ROCM_PATH/llvm/bin ; \
#   rm amdgpu-arch offload-arch ; \
#   g++-12 /h/amdgpu-arch.cpp -DNUM_TARGETS=8 -o amdgpu-arch ; \
#   g++-12 /h/amdgpu-arch.cpp -DNUM_TARGETS=1 -o offload-arch ; \
#   ./amdgpu-arch ; \
#   ./offload-arch ; \
#   bash -eux -o pipefail -c "$REMOVE_CRAY_DEPS"
# ARG RCCL_VERSION=85eb1f1

# RUN $WITH_CONDA ; set -eux ; \
#   pip install cmake==3.28.4

# RUN $WITH_CONDA ; set -eux ; \
#   rm -rf /opt/mybuild ; \
#   git clone https://github.com/rocm/rccl /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $RCCL_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   mkdir /opt/mybuild/build ; \
#   cd  /opt/mybuild/build ; \
#   CXX=$ROCM_PATH/bin/hipcc \
#   cmake \
#     -DBUILD_LOCAL_GPU_TARGET_ONLY=ON \
#     -DCOMPILING_TARGETS=gfx942 \
#     -DENABLE_MSCCLPP=OFF \
#     -DCMAKE_INSTALL_PREFIX=/opt/rccl \
#     -DCMAKE_BUILD_TYPE=Release \
#     .. ; \
#   nice make -j V=1 VERBOSE=1 ; \
#   nice make -j install ; \
#   cd / ; rm -rf /opt/mybuild

# RUN set -eux ; \ 
#   rm -rf $ROCM_PATH/lib/librccl.so* ; \
#   ln -s /opt/rccl/lib/librccl.so* $ROCM_PATH/lib

# RUN set -eux ; \ 
#   cd $ROCM_PATH ; \
#   find -iname '*.cmake' -o -iname '*.txt' | xargs grep -i librccl.so ; \
#   find -iname '*.cmake' -o -iname '*.txt' | xargs sed -E -i 's#librccl.[0-9,a-z,\.]+#librccl.so.1.0#g' ; \
#   find -iname '*.cmake' -o -iname '*.txt' | xargs grep -i librccl.so
# # Latest libfabric build
# ARG CASSINI_HEADERS_VERSION=9a8a738a879f007849fbc69be8e3487a4abf0952
# ARG CXI_DRIVER_VERSION=c284516fa8d0027b8f84e8ca818e8c6bbe320bd8
# ARG LIBCXI_VERSION=0f3609b5e224636abffc7ceffe6f4e9c83244c08

# RUN set -eux; \
#   zypper -n refresh ; \
#   zypper --no-gpg-checks -n install -y --force-resolution \
#     libconfig-devel \
#     libuv-devel \
#     fuse-devel  \
#     libyaml-devel \
#     libnl3-devel \
#     libnuma-devel \
#     libsensors4-devel \
#     libcurl-devel \
#     ; zypper clean

# RUN set -eux ; \
#   git clone --recursive https://github.com/HewlettPackard/shs-cassini-headers /opt/cassini-headers ; \
#   git -C /opt/cassini-headers checkout -b mydev $CASSINI_HEADERS_VERSION ; \
#   git clone --recursive https://github.com/HewlettPackard/shs-cxi-driver /opt/cxi-driver ; \
#   git -C /opt/cxi-driver  checkout -b mydev $CXI_DRIVER_VERSION ; \
#   git clone --recursive https://github.com/HewlettPackard/shs-libcxi /opt/shs-libcxi-src ; \
#   git -C /opt/shs-libcxi-src checkout -b mydev $LIBCXI_VERSION ; \
#   export CPATH=/opt/cassini-headers/include:/opt/cxi-driver/include ; \
#   \
#   cd /opt/shs-libcxi-src ; \
#   ./autogen.sh ; \
#   \
#   cd /opt/shs-libcxi-src ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     CFLAGS='-Wno-unused-but-set-variable' \
#       ./configure --prefix=/opt/shs-libcxi --with-rocm=$ROCM_PATH \
#         --without-systemd \
#         --with-systemdsystemunitdir=/opt/shs-libcxi/systemdsystemunitdir \
#         --with-udevrulesdir=/opt/shs-libcxi/udevrulesdir ; \
#   \
#   sed -i "s#/usr/share/cassini-headers#/opt/cassini-headers/share/cassini-headers#g" /opt/shs-libcxi-src/utils/cxi_dump_csrs.py ; \
#   \
#   cd /opt/shs-libcxi-src ; \
#   make VERBOSE=1 V=1 -j ; \
#   make VERBOSE=1 V=1 -j install ; \
#   \
#   mv /opt/shs-libcxi-src/include /opt/shs-libcxi/include ; \
#   cd / ; rm -rf /opt/shs-libcxi-src 

# ENV LD_LIBRARY_PATH=/opt/shs-libcxi/lib:$LD_LIBRARY_PATH
# ENV LIBFABRIC_VERSION "e08d3161b8038ebfa50a4eb5bf76132e4eaeb137"

# RUN set -eux ; \
#   export CPATH=/opt/shs-libcxi/include:/opt/cassini-headers/include:/opt/cxi-driver/include ; \
#   export LIBRARY_PATH=/opt/shs-libcxi/lib ; \
#   \
#   git clone --recursive https://github.com/ofiwg/libfabric /opt/libfabric-src ; \
#   git -C /opt/libfabric-src checkout -b mydev $LIBFABRIC_VERSION ; \
#   \
#   cd /opt/libfabric-src ; \
#   ./autogen.sh ; \
#   \
#   mkdir /opt/libfabric-src/build ; \
#   \
#   cd /opt/libfabric-src/build ; \
#   ../configure CC=gcc-12 --prefix=/opt/libfabric \
#     LDFLAGS=-Wl,--build-id --enable-only \
#     --enable-restricted-dl --enable-tcp --enable-udp --enable-rxm --enable-rxd --enable-hook_debug \
#     --enable-hook_hmem --enable-dmabuf_peer_mem --enable-cxi=/opt/shs-libcxi --enable-gdrcopy-dlopen --with-rocr=$ROCM_PATH ; \
#   \
#   cd /opt/libfabric-src/build ; \
#   nice make V=1 VERBOSE=1 -j  ; \
#   nice make V=1 VERBOSE=1 -j install ; \
#   \
#   cd / ; rm -rf /opt/libfabric-src

# ENV LIBFABRIC_PATH=/opt/libfabric
# ENV LD_LIBRARY_PATH=$LIBFABRIC_PATH/lib:$LD_LIBRARY_PATH
# ARG AWS_PLUGIN_VERSION=17d41cb

# RUN \
#   set -eux ; \
#   bash -eux -o pipefail -c "$DOWNLOAD_CRAY_DEPS" ; \
#   tar -C / -xf /h/cpe-$CPE_VERSION.tar ; \
#   \
#   git clone -b cxi https://github.com/rocm/aws-ofi-rccl /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $AWS_PLUGIN_VERSION ; \
#   git apply < /h/aws.patch ; \
#   ./autogen.sh ; \
#   \
#   cd /opt/mybuild ; \
#   export CPATH=$LIBFABRIC_PATH/include ; \
#   export LIBRARY_PATH=$LD_LIBRARY_PATH ; \
#   LDFLAGS='-L/opt/shs-libcxi/lib -lcxi' CC=gcc-12 ./configure --with-libfabric=$LIBFABRIC_PATH --enable-trace --with-hip=$ROCM_PATH --with-rccl=$ROCM_PATH --disable-tests ; \
#   LDFLAGS='-L/opt/shs-libcxi/lib -lcxi' CC=gcc-12 nice make -j ; \
#   \
#   mkdir /opt/aws-ofi-rccl ; \
#   mv src/.libs/librccl-net.so* /opt/aws-ofi-rccl ; \
#   rm -rf /opt/mybuild ; \
#   bash -eux -o pipefail -c "$REMOVE_CRAY_DEPS" 

# #
# # Add relevant libs to execution environment
# #
# ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:/opt/aws-ofi-rccl
# RUN set -eux ; \
#   bash -eux -o pipefail -c "$DOWNLOAD_CRAY_DEPS" ; \
#   tar -C / -xf /h/cpe-$CPE_VERSION.tar ; \
#   \
#   git clone https://github.com/rocm/rccl-tests /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   RMAJOR=$(echo $ROCM_RELEASE | cut -d '.' -f1) ; \
#   RMINOR=$(echo $ROCM_RELEASE | cut -d '.' -f2) ; \
#   if [ $RMAJOR -lt 6 -o $RMINOR -lt 2 ] ; then \
#     git checkout -b mydev ae3e635 ; \
#   else \
#     git checkout -b mydev 448c4c7 ; \
#   fi ; \
#   sed -i 's/-std=c++14/-std=c++14 --amdgpu-target=gfx942:xnack- --amdgpu-target=gfx942:xnack+/g' /opt/mybuild/src/Makefile ; \
#   \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     DEBUG=$RCCL_DEBUG \
#     CXX=g++-12 \
#     MPI_HOME=$MPICH_PATH \
#     ROCM_PATH=$ROCM_PATH \
#     MPI=1 \
#     NCCL_HOME=$ROCM_PATH/rccl \
#     nice make -j ; \
#   mkdir /opt/rccltests ; \
#   mv /opt/mybuild/build/* /opt/rccltests ; \
#   rm -rf /opt/mybuild ; \
#   bash -eux -o pipefail -c "$REMOVE_CRAY_DEPS" 
  
# #
# # Install miniconda
# #
# RUN set -eux ; \
#   curl -LO https://repo.anaconda.com/miniconda/Miniconda3-py312_24.5.0-0-Linux-x86_64.sh ; \
#   bash ./Miniconda3-* -b -p /opt/miniconda3 -s ; \
#   rm -rf ./Miniconda3-*

# ENV WITH_CONDA "source /opt/miniconda3/bin/activate base"
# #
# # Install conda environment
# # 
# ARG PYTHON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   conda create -n pytorch python=$PYTHON_VERSION ; \
#   conda activate pytorch ; \
#   conda install -y ninja pillow cmake pyyaml
# ENV WITH_CONDA "source /opt/miniconda3/bin/activate pytorch"

# # Repository for the wheel files
# RUN set -eux ; \
#   mkdir /opt/wheels
  
# #
# # Install pytorch
# # 

# # PyTorch comes with RCCL from ROCm 6.0.0 which cause a segmentation fault 
# # in the tests. It's supspected it's related to https://github.com/ROCm/rccl/pull/1153
# # Copying the RCCL library from /opt/rocm, solve the issue.

# ENV PYTORCH_ROCM_ARCH gfx942
# ARG PYTORCH_VERSION
# ARG PYTORCH_DEBUG
# ARG PYTORCH_RELWITHDEBINFO

# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torch==${PYTORCH_VERSION} --index-url https://download.pytorch.org/whl/

# RUN $WITH_CONDA; set -eux ; \
#   python -c 'import torch; print(torch.__file__)'

# # Problematic for RCCL to use conda libstdc++.so from conda.
# RUN $WITH_CONDA ; set -eux ; \
#   rm $CONDA_PREFIX/lib/libstdc++.*

# RUN $WITH_CONDA; set -eux ; \
#   cp /opt/rocm/lib/librccl.so $(dirname $(python -c 'import torch; print(torch.__file__)'))/lib
  
# #
# # Pytorch dependencies
# #
# RUN $WITH_CONDA; set -eux ; \
#   pip install packaging

# ARG APEX_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   cd / ; \
#   rm -rf /opt/mybuild ; \
#   git clone --recursive https://github.com/rocm/apex /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $APEX_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   \
#   # cp /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h \
#   #    /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h.orig ; \
#   # sed -i 's#defined(TORCH_HIP_VERSION)#defined(USE_ROCM)#g' \
#   #   /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h ; \
#   # \
#   TORCH_DONT_CHECK_COMPILER_ABI=1 \
#     CC=clang \
#     CXX=clang++ \
#     nice python setup.py bdist_wheel --cpp_ext --cuda_ext ; \
#   \
#   # cp /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h.orig \
#   #    /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h ; \
#   # \
#   cp -rf dist/* /opt/wheels ; \
#   rm -rf /opt/mybuild
  
# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/apex-*.whl

# ARG TORCHVISION_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchvision==$TORCHVISION_VERSION --index-url https://download.pytorch.org/whl/

# #
# # AMD-SMI
# #
# RUN $WITH_CONDA; set -eux ; \
#   cd $ROCM_PATH/share/amd_smi ; \
#   python3 -m pip wheel . --wheel-dir=/opt/wheels ; \
#   pip install /opt/wheels/amdsmi-*.whl

# ARG TORCHDATA_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchdata==$TORCHDATA_VERSION --index-url https://download.pytorch.org/whl/
   
# ARG TORCHTEXT_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchtext==$TORCHTEXT_VERSION --index-url https://download.pytorch.org/whl/

# ARG TORCHAUDIO_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchaudio==${TORCHAUDIO_VERSION} --index-url https://download.pytorch.org/whl/

# #
# # Deepspeed
# #
# ENV RUSTUP_HOME /opt/rust
# ENV CARGO_HOME /opt/rust
# RUN set -eux ; \
#   curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs > /opt/rust.sh ; \
#   sh /opt/rust.sh -y --no-modify-path ; \
#   rm -rf /opt/rust.sh

# ENV PATH $PATH:/opt/rust/bin

# RUN $WITH_CONDA; set -eux ; \
#   conda install -y  -c conda-forge oneccl-devel

# ARG DEEPSPEED_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   ln -s $(which gcc-12) /opt/rust/bin/cc ; \
#   CC=gcc-12 CXX=g++-12 \
#   DS_BUILD_AIO=0 \
#   DS_BUILD_CCL_COMM=1 \
#   DS_BUILD_CPU_ADAM=1 \
#   DS_BUILD_CPU_LION=1 \
#   DS_BUILD_EVOFORMER_ATTN=0 \
#   DS_BUILD_FUSED_ADAM=1 \
#   DS_BUILD_FUSED_LION=1 \
#   DS_BUILD_CPU_ADAGRAD=0 \
#   DS_BUILD_FUSED_LAMB=1 \
#   DS_BUILD_QUANTIZER=0 \
#   DS_BUILD_RANDOM_LTD=0 \
#   DS_BUILD_SPARSE_ATTN=0 \
#   DS_BUILD_TRANSFORMER=0 \
#   DS_BUILD_TRANSFORMER_INFERENCE=0 \
#   DS_BUILD_STOCHASTIC_TRANSFORMER=1 \
#   DS_ACCELERATOR=cuda \
#   pip install deepspeed==$DEEPSPEED_VERSION --global-option="build_ext" --global-option="-j32" ; \
# #  ds_report ; \
#   true

# #
# # flash-attention
# #
# ARG FLASH_ATTENTION_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $FLASH_ATTENTION_VERSION --recursive https://github.com/Dao-AILab/flash-attention /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   cp -rf benchmarks /opt/wheels/flash_attn-benchmarks ; \
#   \
#   rm -rf build ; \
#   MAX_JOBS=32 \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   GPU_ARCHS="gfx942" \
#     python setup.py bdist_wheel ; \
#   cp -rf dist/* /opt/wheels ; \
#   \
#   rm -rf /opt/mybuild 

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/flash_attn-*.whl

# #
# # xformers
# #
# ARG XFORMERS_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive https://github.com/ROCm/xformers /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $XFORMERS_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   \
#   rm -rf build ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   HIP_ARCHITECTURES="gfx942" \
#   PYTORCH_ROCM_ARCH="gfx942" \
#   python setup.py bdist_wheel ; \
#   cp -rf dist/* /opt/wheels ; \
#   \
#   rm -rf /opt/mybuild 

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/xformers-*.whl

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     scipy==1.12.0 \
#     matplotlib==3.8.2 \
#     pandas==2.2.2 \
#     seaborn==0.13.2

# # 
# # Bits and bytes
# #
# ARG BITS_AND_BYTES_VERSION
# RUN $WITH_CONDA; set -eux ; \ 
#   git clone https://github.com/ROCm/bitsandbytes /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $BITS_AND_BYTES_VERSION ; \
#   cmake -DCOMPUTE_BACKEND=hip -DBNB_ROCM_ARCH="gfx942" -S . ; \
#   nice make -j ; \
#   python setup.py bdist_wheel ; \
#   cp dist/bitsandbytes-*.whl /opt/wheels ; \
#   \
#   cd / ; \
#   rm -rf /opt/mybuild ; \
#   true

# RUN $WITH_CONDA; set -eux ; \ 
#   pip install /opt/wheels/bitsandbytes-*.whl

# #
# # Some other packages we may need
# #
# RUN $WITH_CONDA; set -eux ; \ 
#   pip install \
#     'numpy<2' \
#     transformers==4.46.3 \
#     sentencepiece==0.2.0 \
#     protobuf==5.27.1 \
#     accelerate==0.34.2 \
#     tensorboard==2.18.0 \
#     openpyxl==3.1.5

# #
# # VLLM
# #
# RUN $WITH_CONDA; set -eux ; \ 
#   pip install \
#     setuptools_scm ; \
#   pip install --upgrade \ 
#     setuptools>=77.0.3

# ARG VLLM_VERSION
# RUN $WITH_CONDA ; set -eux ; \
#   git clone --recursive -b $VLLM_VERSION https://github.com/vllm-project/vllm /opt/mybuild ; \
#   \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   \
#   rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     /opt/wheels/vllm-*.whl

# #
# # LLVM compression dependencies 
# #
# RUN set -eux; \
#   zypper -n refresh ; \
#   zypper --no-gpg-checks -n install -y --force-resolution \
#     libzstd-devel ; \
#   zypper clean

# #
# # LLVM triton uses - otherwise it will download binaries with glibc compatibility issues
# # maybe need zstd: make CC=gcc-12 CXX=g++-12 PREFIX=/aotriton/zstd -j install
# #
# ARG TRITON_LLVM_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/llvm/llvm-project /opt/llvm-project ; \
#   cd /opt/llvm-project ; \
#   git checkout -b mydev $TRITON_LLVM_VERSION ; \
#   \
#   mkdir /opt/llvm-project/build ; \
#   cd /opt/llvm-project/build ; \
#   \
#   cmake -G Ninja \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DLLVM_ENABLE_ASSERTIONS=ON \
#     -DLLVM_ENABLE_PROJECTS="mlir;llvm;lld" \
#     -DLLVM_TARGETS_TO_BUILD="host;NVPTX;AMDGPU" \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 \
#     ../llvm ; \
#   ninja ; \
#   \
#   # for i in /opt/llvm-project/* ; do \
#   #   if [ $i = "/opt/llvm-project/build" ] ; then continue ; else rm -rf $i ; fi ; \
#   # done ; \
#   true

# ARG TRITON_FINAL_LLVM_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/llvm/llvm-project /opt/llvm-project-final ; \
#   cd /opt/llvm-project-final ; \
#   git checkout -b mydev $TRITON_FINAL_LLVM_VERSION ; \
#   \
#   mkdir /opt/llvm-project-final/build ; \
#   cd /opt/llvm-project-final/build ; \
#   \
#   cmake -G Ninja \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DLLVM_ENABLE_ASSERTIONS=ON \
#     -DLLVM_ENABLE_PROJECTS="mlir;llvm;lld" \
#     -DLLVM_TARGETS_TO_BUILD="host;NVPTX;AMDGPU" \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 \
#     ../llvm ; \
#   ninja ; \
#   \
#   # for i in /opt/llvm-project-final/* ; do \
#   #   if [ $i = "/opt/llvm-project-final/build" ] ; then continue ; else rm -rf $i ; fi ; \
#   # done ; \
#   true

# #
# # Triton that AOTRITON uses is built by it, so we used the final one
# # Note that there is already triton that came with Pytorch.
# #
# # Use this LLVM so that aotriton works.
# ENV LLVM_BUILD_DIR=/opt/llvm-project/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG TRITON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $TRITON_VERSION --recursive https://github.com/rocm/triton /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     pip wheel --no-deps -e . -w /opt/wheels ; \
#     cd / ; rm -rf /opt/mybuild

# # RUN $WITH_CONDA; set -eux ; \
# #     pip install /opt/wheels/triton-*.whl ; \
# #     true

# # Use this LLVM so that aotriton works.
# ENV LLVM_BUILD_DIR=/opt/llvm-project-final/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG TRITON_FINAL_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive https://github.com/triton-lang/triton /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $TRITON_FINAL_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     pip wheel --no-deps -e python -w /opt/wheels ; \
#     cd / ; rm -rf /opt/mybuild

# # Install after aotriton is built so it does not conflict.
# # RUN $WITH_CONDA; set -eux ; \
# #     pip install /opt/wheels/triton-*.whl ; \
# #     true

# #
# # AOTRITON for TE
# # 
# ENV LLVM_BUILD_DIR=/opt/llvm-project/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG AOTRITON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive -b $AOTRITON_VERSION https://github.com/ROCm/aotriton /opt/mybuild; \
#   mkdir /opt/mybuild/build ; \
#   cd /opt/mybuild/build ; \
#   \
#   echo '#!/bin/bash -eux' > clang++ ; \
#   echo 'exec $ROCM_PATH/llvm/bin/clang++ -Wno-deprecated-declarations $@' >> clang++ ; \
#   chmod +x clang++ ; \
#   export PATH=$(pwd):$PATH ; \
#   \
#   cmake .. \
#     -DCMAKE_INSTALL_PREFIX=/opt/aotriton \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DAOTRITON_GPU_BUILD_TIMEOUT=0 \
#     -DAOTRITON_TARGET_ARCH=gfx942 \
#     -DAMDGPU_TARGETS=gfx942 \
#     -G Ninja \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 ; \
#   \
#   ninja install ; \
#   \
#   cd / ; rm -rf /opt/mybuild

# ENV LD_LIBRARY_PATH /opt/aotriton/lib:$LD_LIBRARY_PATH

# #
# # Add aiter for vLLM
# #
# ARG AITER_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/ROCm/aiter /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $AITER_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
# #  sed -i 's#{__package__}.{md_name}#private_{__package__}.{md_name}#g' aiter/jit/core.py ; \
#   CC=clang \
#   CXX=clang++ \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/aiter*.whl

# #
# # Transformer engine
# #
# ARG TE_VERSION

# ENV NVTE_FRAMEWORK pytorch
# ENV NVTE_ROCM_ARCH gfx942
# ENV NVTE_AOTRITON_PATH /opt/aotriton
# #ENV NVTE_FUSED_ATTN_CK 0

# RUN $WITH_CONDA; set -eux ; \
#   export GPU_TARGETS=gfx942 ; \
#   export TARGET_GPUS=MI300A  ; \
#   rm -rf /opt/mybuild ; \
#   git clone --recursive https://github.com/ROCm/TransformerEngine.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $TE_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
#   \
#   echo '#!/bin/bash -eux' > clang++ ; \
#   echo 'exec $ROCM_PATH/llvm/bin/clang++ -Wno-c++11-narrowing $@' >> clang++ ; \
#   chmod +x clang++ ; \
#   export PATH=$(pwd):$PATH ; \
#   \
#   sed -i 's/_TEprivate//g' /opt/mybuild/transformer_engine/common/CMakeLists.txt ; \
#   CC=clang \
#     CXX=clang++ \
#     TORCH_DONT_CHECK_COMPILER_ABI=1 \
#     pip wheel --no-deps --verbose -e . -w /opt/wheels ; \
#   rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     /opt/wheels/transformer_engine-*.whl

# # force all RCCL streams to be high priority
# ENV TORCH_NCCL_HIGH_PRIORITY 1
# ENV RCCL_MSCCL_ENABLE 0

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip3 install \
#     scipy \
#     einops \
#     flask-restful \
#     nltk \
#     pytest \
#     pytest-cov \
#     pytest_mock \
#     pytest-csv \
#     pytest-random-order \
#     sentencepiece \
#     wrapt \
#     zarr \
#     wandb \
#     tensorstore==0.1.45 \
#     pytest_mock \
#     pybind11 \
#     setuptools \
#     datasets \
#     tiktoken \
#     pynvml

# RUN $WITH_CONDA; set -eux ; \
#   pip3 install "huggingface_hub[cli]"

# # Is this needed? 
# # RUN $WITH_CONDA; set -eux ; \
# #   python3 -m nltk.downloader punkt_tab

# ENV CAUSAL_CONV1D_FORCE_BUILD=TRUE
# ENV MAMBA_FORCE_BUILD=TRUE
# ENV HIP_ARCHITECTURES=gfx942

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/Dao-AILab/causal-conv1d /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/state-spaces/mamba /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# # For transformer engine.
# ENV NVTE_USE_HIPBLASLT=1

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/caaatch22/grouped_gemm.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout rocm ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/causal_conv1d-*.whl ; \
#   true

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/mamba_ssm-*.whl ; \
#   true

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/grouped_gemm-*.whl ; \
#   true

# ARG MEGATRON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/ROCm/Megatron-LM.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $MEGATRON_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/megatron_core-*.whl ; \
#   true

# #
# # Use Pytorch triton LLVM version
# #
# ENV LLVM_BUILD_DIR=/opt/llvm-project-final/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# RUN $WITH_CONDA; set -eux ; \
#     pip install /opt/wheels/triton-*git${TRITON_FINAL_VERSION:0:8}*.whl
# # Use container libstdc++.so
# RUN $WITH_CONDA; set -eux ; \
#   rm $CONDA_PREFIX/lib/libstdc++.*
# RUN $WITH_CONDA; set -eux ; \
#   cd $(dirname $(python -c "import torch; print(torch.__file__)"))/lib ; \
#   for i in * ; do if [ -f /opt/rocm/lib/$i ] ; then rm $i ; fi ; done ; \
#   for i in * ; do if [ -d /opt/rocm/lib/$i ] ; then rm -rf $i ; fi ; done

# RUN $WITH_CONDA; set -eux ; \
#   cd $(dirname $(python -c "import torch; print(torch.__file__)"))/lib ; \
#   for i in * ; do if [ -f /opt/amdgpu/lib64/$i ] ; then rm $i ; fi ; done
# ENV NCCL_SOCKET_IFNAME='hsn'
# ENV NCCL_NET_GDR_LEVEL=PHB

# #
# # Check https://support.hpe.com/hpesc/public/docDisplay?docId=dp00004854en_us&docLocale=en_US for details
# #
# ENV FI_MR_CACHE_MONITOR=userfaultfd
# ENV FI_CXI_DEFAULT_CQ_SIZE=131072
# # These deteriorate performance to lower node count:
# # ENV FI_CXI_RX_MATCH_MODE=software
# # ENV FI_CXI_RDZV_PROTO=alt_read
# # # Increase for larger jobs
# # ENV FI_CXI_REQ_BUF_SIZE=256
# ARG TORCHAO_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchao==$TORCHAO_VERSION --index-url https://download.pytorch.org/whl/
  
# ARG TORCHTUNE_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $TORCHTUNE_VERSION --recursive https://github.com/pytorch/torchtune /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   pip wheel --no-deps -e . -w /opt/wheels ; \
#   pip install /opt/wheels/torchtune-*.whl ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install \
#     beautifulsoup4==4.13.3 \
#     lightning==2.5.1 \
#     evaluate==0.4.3 \
#     fasttext==0.9.3 \
#     scikit-learn==1.6.1 \
#     scikit-image==0.25.2 \
#     gradio==5.23.1 \
#     numba==0.61.2 \
#     pyrsmi==0.2.0 \
#     pysqlite3==0.5.4 \
#     sentence-transformers==3.4.1 \
#     tensorboardX==2.6.2.2 \
#     torch-tb-profiler==0.4.3 \
#     tornado==6.4.2 \
#     tqdm-multiprocess==0.0.11 \
#     zstandard==0.23.0

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install omegaconf==2.4.0.dev3

# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/huggingface/lighteval /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip wheel --no-deps -e . -w /opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install /opt/wheels/lighteval*.whl ; true

# # Gensim will require https://github.com/piskvorky/gensim/pull/3615 being merged
# # Without that it demotes numpy.
# # RUN $WITH_CONDA; set -eux ; \
# #   git clone https://github.com/piskvorky/gensim /opt/mybuild ; \
# #   cd /opt/mybuild ; \
# #   CC=gcc-12 \
# #   CXX=g++-12 \
# #   pip wheel --no-deps -e . -w /opt/wheels ; \
# #   cd / ; rm -rf /opt/mybuild

# # RUN $WITH_CONDA; set -eux ; \
# #   CC=gcc-12 \
# #   CXX=g++-12 \
# #   pip install /opt/wheels/gensim*.whl
# ENV CONDA_DEFAULT_ENV=pytorch
# ENV CONDA_SHLVL=1
# ENV CONDA_EXE="/opt/miniconda3/bin/conda"
# ENV CONDA_PREFIX="/opt/miniconda3/envs/$CONDA_DEFAULT_ENV"
# ENV _CE_M=''
# ENV CONDA_PYTHON_EXE="/opt/miniconda3/bin/python"
# ENV _CE_CONDA=''
# ENV CONDA_PROMPT_MODIFIER="($CONDA_DEFAULT_ENV)"
# ENV PATH="/opt/miniconda3/envs/$CONDA_DEFAULT_ENV/bin:/opt/miniconda3/condabin:$PATH"

# # Disable the WITH_CONDA helper
# ENV WITH_CONDA=true

# RUN set -eux ; \
#     echo '#!/bin/bash' > /entry.sh ; \
#     echo 'PATH='"$PATH"' exec "$@"' >> /entry.sh ; \
#     chmod +x /entry.sh

# ENTRYPOINT [ "/entry.sh" ]
# CMD [ "/bin/bash" ]