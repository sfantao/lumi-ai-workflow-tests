FROM ubuntu:noble-20250925

RUN set -eux ; \
  apt-get update ; \
  apt-get -y install \
    git cmake gcc g++ gfortran numactl gawk patch tar autoconf automake libtool nano which gpg less \
    zlib1g-dev libncurses-dev graphviz wget ; \
  apt-get clean ; \
  rm -rf /var/lib/apt/lists/* ; \
  true

RUN set -eux ; \
# Make the directory if it doesn't exist yet.
# This location is recommended by the distribution maintainers.
  mkdir --parents --mode=0755 /etc/apt/keyrings ; \
# Download the key, convert the signing-key to a full
# keyring required by apt and store in the keyring directory
  wget https://repo.radeon.com/rocm/rocm.gpg.key -O - | \
    gpg --dearmor | tee /etc/apt/keyrings/rocm.gpg > /dev/null

ENV ROCM_RELEASE_MAJOR 7
ENV ROCM_RELEASE_MINOR 0
ENV ROCM_RELEASE_PATCH 2
ENV ROCM_RELEASE $ROCM_RELEASE_MAJOR.$ROCM_RELEASE_MINOR.$ROCM_RELEASE_PATCH

RUN set -eux ; \
  export $(grep DISTRIB_CODENAME /etc/lsb-release) ; \
  echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/$ROCM_RELEASE $DISTRIB_CODENAME main" >> /etc/apt/sources.list.d/rocm.list ; \
  echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/graphics/$ROCM_RELEASE/ubuntu $DISTRIB_CODENAME main" >> /etc/apt/sources.list.d/rocm.list ; \
  true

RUN set -eux ; \
  echo 'Package: *' >> /etc/apt/preferences.d/rocm-pin-600 ; \
  echo 'Pin: release o=repo.radeon.com' >> /etc/apt/preferences.d/rocm-pin-600 ; \
  echo 'Pin-Priority: 600' >> /etc/apt/preferences.d/rocm-pin-600 ; \
  true

ARG MI_TARGET
RUN set -eux ; \
  apt-get update ; \
  apt-get -y install \
    rocm \
    rocm-developer-tools \
    rocm-hip-runtime-dev \
    rocm-hip-sdk \
    rocm-ml-sdk \
    rocm-openmp-sdk \
    miopen-hip-${MI_TARGET}kdb; \
  apt-get clean ; \
  rm -rf /var/lib/apt/lists/* ; \
  true

#
# ROCm environment
#
ENV ROCM_PATH /opt/rocm-$ROCM_RELEASE
ENV PATH $ROCM_PATH/bin:$ROCM_PATH/llvm/bin:$PATH
ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:$ROCM_PATH/lib

COPY rocm_agent_enumerator $ROCM_PATH/bin/
COPY rocminfo $ROCM_PATH/bin/
COPY amdgpu-arch.cpp $ROCM_PATH/llvm/bin/

RUN set -eux ; \
  chmod +x $ROCM_PATH/bin/rocm_agent_enumerator ; \
  chmod +x $ROCM_PATH/bin/rocminfo ; \
  \
  cd $ROCM_PATH/llvm/bin ; \
  g++ amdgpu-arch.cpp -DNUM_TARGETS=8 -o amdgpu-arch ; \
  g++ amdgpu-arch.cpp -DNUM_TARGETS=1 -o offload-arch ; \
  ./amdgpu-arch ; \
  ./offload-arch ; \
  true

#
# RCCL development 
#
ARG RCCL_VERSION
RUN $WITH_CONDA ; set -eux ; \
  rm -rf /opt/mybuild ; \
  git clone https://github.com/rocm/rccl /opt/mybuild ; \
  cd /opt/mybuild ; \
  git checkout -b mydev $RCCL_VERSION ; \
  git submodule sync ; \
  git submodule update --init --recursive  ; \
  mkdir /opt/mybuild/build ; \
  cd  /opt/mybuild/build ; \
  CXX=$ROCM_PATH/bin/hipcc \
  cmake \
    -DBUILD_LOCAL_GPU_TARGET_ONLY=ON \
    -DCOMPILING_TARGETS=$MI_TARGET \
    -DENABLE_MSCCLPP=OFF \
    -DCMAKE_INSTALL_PREFIX=/opt/rccl \
    -DCMAKE_BUILD_TYPE=Release \
    .. ; \
  nice make -j V=1 VERBOSE=1 ; \
  nice make -j install ; \
  cd / ; rm -rf /opt/mybuild

RUN set -eux ; \ 
  mkdir /opt/rccl-original ; \
  mv $ROCM_PATH/lib/librccl.so* /opt/rccl-original ; \
  ln -s /opt/rccl/lib/librccl.so* $ROCM_PATH/lib

RUN set -eux ; \ 
  ls -la /opt/rccl/lib/librccl.so* ; \
  cd $ROCM_PATH ; \
  find -iname '*.cmake' -o -iname '*.txt' | xargs grep -i librccl.so ; \
  find -iname '*.cmake' -o -iname '*.txt' | xargs sed -E -i 's#librccl.[0-9,a-z,\.]+#librccl.so.1.0#g' ; \
  find -iname '*.cmake' -o -iname '*.txt' | xargs grep -i librccl.so

ENV NCCL_SOCKET_IFNAME='hsn0,hsn1,hsn2,hsn3'
ENV NCCL_NET_GDR_LEVEL=PHB
ENV NCCL_NET_PLUGIN=librccl-net.so

#
# Latest libfabric build
#

RUN set -eux ; \
  apt-get update ; \
  apt-get -y install \
    libconfig-dev \
    libuv1-dev \
    libfuse-dev \
    libyaml-dev \
    libnl-3-dev \
    libnuma-dev \
    libsensors-dev \
    libcurl4-openssl-dev \
    libjson-c-dev \
    curl ; \
  apt-get clean ; \
  rm -rf /var/lib/apt/lists/* ; \
  true

ARG CASSINI_HEADERS_VERSION
ARG CXI_DRIVER_VERSION
ARG LIBCXI_VERSION

RUN set -eux ; \
  git clone --recursive https://github.com/HewlettPackard/shs-cassini-headers /opt/cassini-headers ; \
  git -C /opt/cassini-headers checkout -b mydev $CASSINI_HEADERS_VERSION ; \
  git clone --recursive https://github.com/HewlettPackard/shs-cxi-driver /opt/cxi-driver ; \
  git -C /opt/cxi-driver  checkout -b mydev $CXI_DRIVER_VERSION ; \
  git clone --recursive https://github.com/HewlettPackard/shs-libcxi /opt/shs-libcxi-src ; \
  git -C /opt/shs-libcxi-src checkout -b mydev $LIBCXI_VERSION ; \
  export CPATH=/opt/cassini-headers/include:/opt/cxi-driver/include ; \
  \
  cd /opt/shs-libcxi-src ; \
  ./autogen.sh ; \
  \
  cd /opt/shs-libcxi-src ; \
  CC=gcc \
    CXX=g++ \
    CFLAGS='-Wno-unused-but-set-variable' \
      ./configure --prefix=/opt/shs-libcxi --with-rocm=$ROCM_PATH \
        --without-systemd \
        --with-systemdsystemunitdir=/opt/shs-libcxi/systemdsystemunitdir \
        --with-udevrulesdir=/opt/shs-libcxi/udevrulesdir ; \
  \
  sed -i "s#/usr/share/cassini-headers#/opt/cassini-headers/share/cassini-headers#g" /opt/shs-libcxi-src/utils/cxi_dump_csrs.py ; \
  \
  cd /opt/shs-libcxi-src ; \
  make VERBOSE=1 V=1 -j ; \
  make VERBOSE=1 V=1 -j install ; \
  \
  mv /opt/shs-libcxi-src/include /opt/shs-libcxi/include ; \
  cd / ; rm -rf /opt/shs-libcxi-src 

ENV LD_LIBRARY_PATH=/opt/shs-libcxi/lib:$LD_LIBRARY_PATH

ARG LIBFABRIC_VERSION

RUN set -eux ; \
  export CPATH=/opt/shs-libcxi/include:/opt/cassini-headers/include:/opt/cxi-driver/include ; \
  export LIBRARY_PATH=/opt/shs-libcxi/lib ; \
  \
  git clone --recursive https://github.com/ofiwg/libfabric /opt/libfabric-src ; \
  git -C /opt/libfabric-src checkout -b mydev $LIBFABRIC_VERSION ; \
  \
  cd /opt/libfabric-src ; \
  ./autogen.sh ; \
  \
  mkdir /opt/libfabric-src/build ; \
  \
  cd /opt/libfabric-src/build ; \
  ../configure CC=gcc --prefix=/opt/libfabric \
    LDFLAGS=-Wl,--build-id --enable-only \
    --enable-restricted-dl --enable-tcp --enable-udp --enable-rxm --enable-rxd --enable-hook_debug \
    --enable-hook_hmem --enable-dmabuf_peer_mem --enable-cxi=/opt/shs-libcxi --enable-gdrcopy-dlopen --with-rocr=$ROCM_PATH ; \
  \
  cd /opt/libfabric-src/build ; \
  nice make V=1 VERBOSE=1 -j  ; \
  nice make V=1 VERBOSE=1 -j install ; \
  \
  cd / ; rm -rf /opt/libfabric-src

ENV LIBFABRIC_PATH=/opt/libfabric
ENV LD_LIBRARY_PATH=$LIBFABRIC_PATH/lib:$LD_LIBRARY_PATH

#
# HWLOC
#

ARG HWLOC_VERSION
ARG HWLOC_PATCH_VERSION
RUN set -eux ; \
    cd /opt ;\
    HWLOC_TAR=https://download.open-mpi.org/release/hwloc/v${HWLOC_VERSION}/hwloc-${HWLOC_VERSION}.${HWLOC_PATCH_VERSION}.tar.gz ; \
    curl -LO  $HWLOC_TAR; \
    tar -xzf hwloc-*.tar.gz ; rm -rf hwloc-*.tar.gz ; \
    cd hwloc-${HWLOC_VERSION}.${HWLOC_PATCH_VERSION} ;\
    CC=gcc ./configure --with-rocm=$ROCM_PATH --disable-rsmi --prefix=/opt/hwloc  --localstatedir=/var ;\
    make install ; \
    cd / ; rm -rf hwloc-*

ENV PATH=/opt/hwloc/bin:$PATH
ENV LD_LIBRARY_PATH=/opt/hwloc/lib:$LD_LIBRARY_PATH

#
# PMIX
# 
# RUN set -eux ; \
#   apt-get update ; \
#   apt-get -y install \
#     libevent-dev ; \
#   apt-get clean ; \
#   rm -rf /var/lib/apt/lists/* ; \
#   true

# ARG PMIX_VERSION

# RUN set -eux ; \
#   cd /opt ; \
#   curl -LO https://github.com/openpmix/openpmix/releases/download/v$PMIX_VERSION/pmix-$PMIX_VERSION.tar.gz ; \
#   tar -xf pmix-*.tar.gz ; rm -rf pmix-*.tar.gz  ; \
#   cd pmix-* ; \
#   ./configure --prefix=/opt/pmix --with-hwloc=/opt/hwloc --enable-shared ; \
#   make -j ; \
#   make -j install ; \
#   \
#   cd /opt ; rm -rf pmix-* ; \
#   true

#
# Add MPICH
#

RUN set -eux ; \
  apt-get update ; \
  apt-get -y install \
    libpmi2-0-dev \
    libpmix-dev ; \
  apt-get clean ; \
  rm -rf /var/lib/apt/lists/* ; \
  true

ARG MPICH_VERSION
ENV MPICH_PATH=/opt/mpich

RUN set -eux ; \
    cd /opt ; \
    MPICH_TAR=https://www.mpich.org/static/downloads/${MPICH_VERSION}/mpich-${MPICH_VERSION}.tar.gz ; \
    curl -LO  $MPICH_TAR ; \
    tar -xzf mpich-$MPICH_VERSION.tar.gz; rm -rf mpich-$MPICH_VERSION.tar.gz ; \
    cd /opt/mpich-* ;\
    export CPATH=/usr/include/slurm:/usr/lib/x86_64-linux-gnu/pmix2/include ; \
    CC=gcc CXX=g++  \
        ./configure --prefix=$MPICH_PATH  \
            --with-hip-lib=$ROCM_PATH/lib/  \
            --with-hip-include=$ROCM_PATH/include/  \
            --with-libfabric=/opt/libfabric  \
            --disable-fortran \
            --enable-fast=all,O3  \
            --with-device=ch4:ofi:cxi \
            --with-pm=no \
            --disable-silent-rules \
            --enable-debuginfo \
            --with-hwloc=/opt/hwloc \
            --enable-shared --with-pmi2 --with-pmix ;\
    make -j ;\
    make install ; \
    cd / ; rm -rf /opt/mpich-*

ENV PATH=$MPICH_PATH/bin:$PATH
ENV LD_LIBRARY_PATH=$MPICH_PATH/lib:$LD_LIBRARY_PATH

#
# CXI plugin HPE and AWS versions
#
ARG CXI_PLUGIN_VERSION
RUN set -eux ; \
  git clone https://github.com/HewlettPackard/open-ofi-xccl.git /opt/cxi-plugin-src ; \
  cd /opt/cxi-plugin-src ; \
  git checkout -b mydev ${CXI_PLUGIN_VERSION} ; \
  ./autogen.sh ; \  
  CC=gcc ./configure \
    --with-rocm=${ROCM_PATH} \
    --prefix=/opt/cxi-plugin \
    --with-rccl=/opt/rccl \
    --with-libfabric=/opt/libfabric \
    --with-hwloc=/opt/hwloc ; \
  make -j install ; \
  cd / ; rm -rf /opt/cxi-plugin-src
  
ARG CXI_PLUGIN_AWS_VERSION
RUN set -eux ; \
  git clone https://github.com/aws/aws-ofi-nccl /opt/cxi-plugin-aws-src ; \
  cd /opt/cxi-plugin-aws-src ; \
  git checkout -b mydev ${CXI_PLUGIN_AWS_VERSION} ; \
  ./autogen.sh ; \  
  CC=gcc ./configure \
    --with-rocm=${ROCM_PATH} \
    --prefix=/opt/cxi-plugin-aws \
    --with-rccl=/opt/rccl \
    --with-libfabric=/opt/libfabric \
    --with-hwloc=/opt/hwloc ; \
  make -j install ; \
  cd / ; rm -rf /opt/cxi-plugin-aws-src

ENV LD_LIBRARY_PATH $LD_LIBRARY_PATH:/opt/cxi-plugin-aws/lib:/opt/cxi-plugin/lib
ENV OFI_NCCL_PROTOCOL=sendrecv

#
# Check https://support.hpe.com/hpesc/public/docDisplay?docId=dp00004854en_us&docLocale=en_US for details
#
ENV FI_MR_CACHE_MONITOR=userfaultfd
ENV FI_CXI_DEFAULT_CQ_SIZE=131072
# These deteriorate performance to lower node count:
# ENV FI_CXI_RX_MATCH_MODE=software
# ENV FI_CXI_RDZV_PROTO=alt_read
# # Increase for larger jobs
# ENV FI_CXI_REQ_BUF_SIZE=256

#
# RCCL tests
#

#
# Add relevant libs to execution environment
#
ARG RCCL_TESTS_VERSION
RUN set -eux ; \
  git clone https://github.com/rocm/rccl-tests /opt/mybuild ; \
  cd /opt/mybuild ; \
  git checkout -b mydev $RCCL_TESTS_VERSION ; \
  \
  cd /opt/mybuild ; \
  CC=gcc \
    CXX=g++ \
    MPI_HOME=$MPICH_PATH \
    ROCM_PATH=$ROCM_PATH \
    MPI=1 \
    NCCL_HOME=$ROCM_PATH/rccl \
    GPU_TARGETS=${MI_TARGET} \
    nice make V=1 VERBOSE=1 -j ; \
  mkdir /opt/rccltests ; \
  mv /opt/mybuild/build/* /opt/rccltests ; \
  rm -rf /opt/mybuild 

# #
# # Install miniconda
# #
# RUN set -eux ; \
#   curl -LO https://repo.anaconda.com/miniconda/Miniconda3-py312_24.5.0-0-Linux-x86_64.sh ; \
#   bash ./Miniconda3-* -b -p /opt/miniconda3 -s ; \
#   rm -rf ./Miniconda3-*

# ENV WITH_CONDA "source /opt/miniconda3/bin/activate base"
# #
# # Install conda environment
# # 
# ARG PYTHON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   conda create -n pytorch python=$PYTHON_VERSION ; \
#   conda activate pytorch ; \
#   conda install -y ninja pillow cmake pyyaml
# ENV WITH_CONDA "source /opt/miniconda3/bin/activate pytorch"

# # Repository for the wheel files
# RUN set -eux ; \
#   mkdir /opt/wheels
  
# #
# # Install pytorch
# # 

# # PyTorch comes with RCCL from ROCm 6.0.0 which cause a segmentation fault 
# # in the tests. It's supspected it's related to https://github.com/ROCm/rccl/pull/1153
# # Copying the RCCL library from /opt/rocm, solve the issue.

# ENV PYTORCH_ROCM_ARCH gfx942
# ARG PYTORCH_VERSION
# ARG PYTORCH_DEBUG
# ARG PYTORCH_RELWITHDEBINFO

# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torch==${PYTORCH_VERSION} --index-url https://download.pytorch.org/whl/

# RUN $WITH_CONDA; set -eux ; \
#   python -c 'import torch; print(torch.__file__)'

# # Problematic for RCCL to use conda libstdc++.so from conda.
# RUN $WITH_CONDA ; set -eux ; \
#   rm $CONDA_PREFIX/lib/libstdc++.*

# RUN $WITH_CONDA; set -eux ; \
#   cp /opt/rocm/lib/librccl.so $(dirname $(python -c 'import torch; print(torch.__file__)'))/lib
  
# #
# # Pytorch dependencies
# #
# RUN $WITH_CONDA; set -eux ; \
#   pip install packaging

# ARG APEX_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   cd / ; \
#   rm -rf /opt/mybuild ; \
#   git clone --recursive https://github.com/rocm/apex /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $APEX_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   \
#   # cp /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h \
#   #    /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h.orig ; \
#   # sed -i 's#defined(TORCH_HIP_VERSION)#defined(USE_ROCM)#g' \
#   #   /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h ; \
#   # \
#   TORCH_DONT_CHECK_COMPILER_ABI=1 \
#     CC=clang \
#     CXX=clang++ \
#     nice python setup.py bdist_wheel --cpp_ext --cuda_ext ; \
#   \
#   # cp /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h.orig \
#   #    /opt/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/include/torch/csrc/cuda/CUDAPluggableAllocator.h ; \
#   # \
#   cp -rf dist/* /opt/wheels ; \
#   rm -rf /opt/mybuild
  
# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/apex-*.whl

# ARG TORCHVISION_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchvision==$TORCHVISION_VERSION --index-url https://download.pytorch.org/whl/

# #
# # AMD-SMI
# #
# RUN $WITH_CONDA; set -eux ; \
#   cd $ROCM_PATH/share/amd_smi ; \
#   python3 -m pip wheel . --wheel-dir=/opt/wheels ; \
#   pip install /opt/wheels/amdsmi-*.whl

# ARG TORCHDATA_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchdata==$TORCHDATA_VERSION --index-url https://download.pytorch.org/whl/
   
# ARG TORCHTEXT_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchtext==$TORCHTEXT_VERSION --index-url https://download.pytorch.org/whl/

# ARG TORCHAUDIO_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchaudio==${TORCHAUDIO_VERSION} --index-url https://download.pytorch.org/whl/

# #
# # Deepspeed
# #
# ENV RUSTUP_HOME /opt/rust
# ENV CARGO_HOME /opt/rust
# RUN set -eux ; \
#   curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs > /opt/rust.sh ; \
#   sh /opt/rust.sh -y --no-modify-path ; \
#   rm -rf /opt/rust.sh

# ENV PATH $PATH:/opt/rust/bin

# RUN $WITH_CONDA; set -eux ; \
#   conda install -y  -c conda-forge oneccl-devel

# ARG DEEPSPEED_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   ln -s $(which gcc-12) /opt/rust/bin/cc ; \
#   CC=gcc-12 CXX=g++-12 \
#   DS_BUILD_AIO=0 \
#   DS_BUILD_CCL_COMM=1 \
#   DS_BUILD_CPU_ADAM=1 \
#   DS_BUILD_CPU_LION=1 \
#   DS_BUILD_EVOFORMER_ATTN=0 \
#   DS_BUILD_FUSED_ADAM=1 \
#   DS_BUILD_FUSED_LION=1 \
#   DS_BUILD_CPU_ADAGRAD=0 \
#   DS_BUILD_FUSED_LAMB=1 \
#   DS_BUILD_QUANTIZER=0 \
#   DS_BUILD_RANDOM_LTD=0 \
#   DS_BUILD_SPARSE_ATTN=0 \
#   DS_BUILD_TRANSFORMER=0 \
#   DS_BUILD_TRANSFORMER_INFERENCE=0 \
#   DS_BUILD_STOCHASTIC_TRANSFORMER=1 \
#   DS_ACCELERATOR=cuda \
#   pip install deepspeed==$DEEPSPEED_VERSION --global-option="build_ext" --global-option="-j32" ; \
# #  ds_report ; \
#   true

# #
# # flash-attention
# #
# ARG FLASH_ATTENTION_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $FLASH_ATTENTION_VERSION --recursive https://github.com/Dao-AILab/flash-attention /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   cp -rf benchmarks /opt/wheels/flash_attn-benchmarks ; \
#   \
#   rm -rf build ; \
#   MAX_JOBS=32 \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   GPU_ARCHS="gfx942" \
#     python setup.py bdist_wheel ; \
#   cp -rf dist/* /opt/wheels ; \
#   \
#   rm -rf /opt/mybuild 

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/flash_attn-*.whl

# #
# # xformers
# #
# ARG XFORMERS_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive https://github.com/ROCm/xformers /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $XFORMERS_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   \
#   rm -rf build ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   HIP_ARCHITECTURES="gfx942" \
#   PYTORCH_ROCM_ARCH="gfx942" \
#   python setup.py bdist_wheel ; \
#   cp -rf dist/* /opt/wheels ; \
#   \
#   rm -rf /opt/mybuild 

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/xformers-*.whl

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     scipy==1.12.0 \
#     matplotlib==3.8.2 \
#     pandas==2.2.2 \
#     seaborn==0.13.2

# # 
# # Bits and bytes
# #
# ARG BITS_AND_BYTES_VERSION
# RUN $WITH_CONDA; set -eux ; \ 
#   git clone https://github.com/ROCm/bitsandbytes /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $BITS_AND_BYTES_VERSION ; \
#   cmake -DCOMPUTE_BACKEND=hip -DBNB_ROCM_ARCH="gfx942" -S . ; \
#   nice make -j ; \
#   python setup.py bdist_wheel ; \
#   cp dist/bitsandbytes-*.whl /opt/wheels ; \
#   \
#   cd / ; \
#   rm -rf /opt/mybuild ; \
#   true

# RUN $WITH_CONDA; set -eux ; \ 
#   pip install /opt/wheels/bitsandbytes-*.whl

# #
# # Some other packages we may need
# #
# RUN $WITH_CONDA; set -eux ; \ 
#   pip install \
#     'numpy<2' \
#     transformers==4.46.3 \
#     sentencepiece==0.2.0 \
#     protobuf==5.27.1 \
#     accelerate==0.34.2 \
#     tensorboard==2.18.0 \
#     openpyxl==3.1.5

# #
# # VLLM
# #
# RUN $WITH_CONDA; set -eux ; \ 
#   pip install \
#     setuptools_scm ; \
#   pip install --upgrade \ 
#     setuptools>=77.0.3

# ARG VLLM_VERSION
# RUN $WITH_CONDA ; set -eux ; \
#   git clone --recursive -b $VLLM_VERSION https://github.com/vllm-project/vllm /opt/mybuild ; \
#   \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   \
#   rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     /opt/wheels/vllm-*.whl

# #
# # LLVM compression dependencies 
# #
# RUN set -eux; \
#   zypper -n refresh ; \
#   zypper --no-gpg-checks -n install -y --force-resolution \
#     libzstd-devel ; \
#   zypper clean

# #
# # LLVM triton uses - otherwise it will download binaries with glibc compatibility issues
# # maybe need zstd: make CC=gcc-12 CXX=g++-12 PREFIX=/aotriton/zstd -j install
# #
# ARG TRITON_LLVM_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/llvm/llvm-project /opt/llvm-project ; \
#   cd /opt/llvm-project ; \
#   git checkout -b mydev $TRITON_LLVM_VERSION ; \
#   \
#   mkdir /opt/llvm-project/build ; \
#   cd /opt/llvm-project/build ; \
#   \
#   cmake -G Ninja \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DLLVM_ENABLE_ASSERTIONS=ON \
#     -DLLVM_ENABLE_PROJECTS="mlir;llvm;lld" \
#     -DLLVM_TARGETS_TO_BUILD="host;NVPTX;AMDGPU" \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 \
#     ../llvm ; \
#   ninja ; \
#   \
#   # for i in /opt/llvm-project/* ; do \
#   #   if [ $i = "/opt/llvm-project/build" ] ; then continue ; else rm -rf $i ; fi ; \
#   # done ; \
#   true

# ARG TRITON_FINAL_LLVM_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/llvm/llvm-project /opt/llvm-project-final ; \
#   cd /opt/llvm-project-final ; \
#   git checkout -b mydev $TRITON_FINAL_LLVM_VERSION ; \
#   \
#   mkdir /opt/llvm-project-final/build ; \
#   cd /opt/llvm-project-final/build ; \
#   \
#   cmake -G Ninja \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DLLVM_ENABLE_ASSERTIONS=ON \
#     -DLLVM_ENABLE_PROJECTS="mlir;llvm;lld" \
#     -DLLVM_TARGETS_TO_BUILD="host;NVPTX;AMDGPU" \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 \
#     ../llvm ; \
#   ninja ; \
#   \
#   # for i in /opt/llvm-project-final/* ; do \
#   #   if [ $i = "/opt/llvm-project-final/build" ] ; then continue ; else rm -rf $i ; fi ; \
#   # done ; \
#   true

# #
# # Triton that AOTRITON uses is built by it, so we used the final one
# # Note that there is already triton that came with Pytorch.
# #
# # Use this LLVM so that aotriton works.
# ENV LLVM_BUILD_DIR=/opt/llvm-project/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG TRITON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $TRITON_VERSION --recursive https://github.com/rocm/triton /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     pip wheel --no-deps -e . -w /opt/wheels ; \
#     cd / ; rm -rf /opt/mybuild

# # RUN $WITH_CONDA; set -eux ; \
# #     pip install /opt/wheels/triton-*.whl ; \
# #     true

# # Use this LLVM so that aotriton works.
# ENV LLVM_BUILD_DIR=/opt/llvm-project-final/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG TRITON_FINAL_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive https://github.com/triton-lang/triton /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $TRITON_FINAL_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#     CXX=g++-12 \
#     pip wheel --no-deps -e python -w /opt/wheels ; \
#     cd / ; rm -rf /opt/mybuild

# # Install after aotriton is built so it does not conflict.
# # RUN $WITH_CONDA; set -eux ; \
# #     pip install /opt/wheels/triton-*.whl ; \
# #     true

# #
# # AOTRITON for TE
# # 
# ENV LLVM_BUILD_DIR=/opt/llvm-project/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# ARG AOTRITON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone --recursive -b $AOTRITON_VERSION https://github.com/ROCm/aotriton /opt/mybuild; \
#   mkdir /opt/mybuild/build ; \
#   cd /opt/mybuild/build ; \
#   \
#   echo '#!/bin/bash -eux' > clang++ ; \
#   echo 'exec $ROCM_PATH/llvm/bin/clang++ -Wno-deprecated-declarations $@' >> clang++ ; \
#   chmod +x clang++ ; \
#   export PATH=$(pwd):$PATH ; \
#   \
#   cmake .. \
#     -DCMAKE_INSTALL_PREFIX=/opt/aotriton \
#     -DCMAKE_BUILD_TYPE=Release \
#     -DAOTRITON_GPU_BUILD_TIMEOUT=0 \
#     -DAOTRITON_TARGET_ARCH=gfx942 \
#     -DAMDGPU_TARGETS=gfx942 \
#     -G Ninja \
#     -DCMAKE_CXX_COMPILER=g++-12 \
#     -DCMAKE_C_COMPILER=gcc-12 ; \
#   \
#   ninja install ; \
#   \
#   cd / ; rm -rf /opt/mybuild

# ENV LD_LIBRARY_PATH /opt/aotriton/lib:$LD_LIBRARY_PATH

# #
# # Add aiter for vLLM
# #
# ARG AITER_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/ROCm/aiter /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $AITER_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
# #  sed -i 's#{__package__}.{md_name}#private_{__package__}.{md_name}#g' aiter/jit/core.py ; \
#   CC=clang \
#   CXX=clang++ \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/aiter*.whl

# #
# # Transformer engine
# #
# ARG TE_VERSION

# ENV NVTE_FRAMEWORK pytorch
# ENV NVTE_ROCM_ARCH gfx942
# ENV NVTE_AOTRITON_PATH /opt/aotriton
# #ENV NVTE_FUSED_ATTN_CK 0

# RUN $WITH_CONDA; set -eux ; \
#   export GPU_TARGETS=gfx942 ; \
#   export TARGET_GPUS=MI300A  ; \
#   rm -rf /opt/mybuild ; \
#   git clone --recursive https://github.com/ROCm/TransformerEngine.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $TE_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive ; \
#   \
#   echo '#!/bin/bash -eux' > clang++ ; \
#   echo 'exec $ROCM_PATH/llvm/bin/clang++ -Wno-c++11-narrowing $@' >> clang++ ; \
#   chmod +x clang++ ; \
#   export PATH=$(pwd):$PATH ; \
#   \
#   sed -i 's/_TEprivate//g' /opt/mybuild/transformer_engine/common/CMakeLists.txt ; \
#   CC=clang \
#     CXX=clang++ \
#     TORCH_DONT_CHECK_COMPILER_ABI=1 \
#     pip wheel --no-deps --verbose -e . -w /opt/wheels ; \
#   rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install \
#     /opt/wheels/transformer_engine-*.whl

# # force all RCCL streams to be high priority
# ENV TORCH_NCCL_HIGH_PRIORITY 1
# ENV RCCL_MSCCL_ENABLE 0

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip3 install \
#     scipy \
#     einops \
#     flask-restful \
#     nltk \
#     pytest \
#     pytest-cov \
#     pytest_mock \
#     pytest-csv \
#     pytest-random-order \
#     sentencepiece \
#     wrapt \
#     zarr \
#     wandb \
#     tensorstore==0.1.45 \
#     pytest_mock \
#     pybind11 \
#     setuptools \
#     datasets \
#     tiktoken \
#     pynvml

# RUN $WITH_CONDA; set -eux ; \
#   pip3 install "huggingface_hub[cli]"

# # Is this needed? 
# # RUN $WITH_CONDA; set -eux ; \
# #   python3 -m nltk.downloader punkt_tab

# ENV CAUSAL_CONV1D_FORCE_BUILD=TRUE
# ENV MAMBA_FORCE_BUILD=TRUE
# ENV HIP_ARCHITECTURES=gfx942

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/Dao-AILab/causal-conv1d /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/state-spaces/mamba /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# # For transformer engine.
# ENV NVTE_USE_HIPBLASLT=1

# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/caaatch22/grouped_gemm.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout rocm ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/causal_conv1d-*.whl ; \
#   true

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/mamba_ssm-*.whl ; \
#   true

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/grouped_gemm-*.whl ; \
#   true

# ARG MEGATRON_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   rm -rf /opt/mybuild ;\
#   git clone https://github.com/ROCm/Megatron-LM.git /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   git checkout -b mydev $MEGATRON_VERSION ; \
#   git submodule sync ; \
#   git submodule update --init --recursive  ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#     python3 setup.py bdist_wheel --dist-dir=/opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   pip install /opt/wheels/megatron_core-*.whl ; \
#   true

# #
# # Use Pytorch triton LLVM version
# #
# ENV LLVM_BUILD_DIR=/opt/llvm-project-final/build
# ENV LLVM_INCLUDE_DIRS=$LLVM_BUILD_DIR/include
# ENV LLVM_LIBRARY_DIR=$LLVM_BUILD_DIR/lib
# ENV LLVM_SYSPATH=$LLVM_BUILD_DIR

# RUN $WITH_CONDA; set -eux ; \
#     pip install /opt/wheels/triton-*git${TRITON_FINAL_VERSION:0:8}*.whl
# # Use container libstdc++.so
# RUN $WITH_CONDA; set -eux ; \
#   rm $CONDA_PREFIX/lib/libstdc++.*
# RUN $WITH_CONDA; set -eux ; \
#   cd $(dirname $(python -c "import torch; print(torch.__file__)"))/lib ; \
#   for i in * ; do if [ -f /opt/rocm/lib/$i ] ; then rm $i ; fi ; done ; \
#   for i in * ; do if [ -d /opt/rocm/lib/$i ] ; then rm -rf $i ; fi ; done

# RUN $WITH_CONDA; set -eux ; \
#   cd $(dirname $(python -c "import torch; print(torch.__file__)"))/lib ; \
#   for i in * ; do if [ -f /opt/amdgpu/lib64/$i ] ; then rm $i ; fi ; done
# ENV NCCL_SOCKET_IFNAME='hsn'
# ENV NCCL_NET_GDR_LEVEL=PHB

# #
# # Check https://support.hpe.com/hpesc/public/docDisplay?docId=dp00004854en_us&docLocale=en_US for details
# #
# ENV FI_MR_CACHE_MONITOR=userfaultfd
# ENV FI_CXI_DEFAULT_CQ_SIZE=131072
# # These deteriorate performance to lower node count:
# # ENV FI_CXI_RX_MATCH_MODE=software
# # ENV FI_CXI_RDZV_PROTO=alt_read
# # # Increase for larger jobs
# # ENV FI_CXI_REQ_BUF_SIZE=256
# ARG TORCHAO_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   pip3 install --pre torchao==$TORCHAO_VERSION --index-url https://download.pytorch.org/whl/
  
# ARG TORCHTUNE_VERSION
# RUN $WITH_CONDA; set -eux ; \
#   git clone -b $TORCHTUNE_VERSION --recursive https://github.com/pytorch/torchtune /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   pip wheel --no-deps -e . -w /opt/wheels ; \
#   pip install /opt/wheels/torchtune-*.whl ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install \
#     beautifulsoup4==4.13.3 \
#     lightning==2.5.1 \
#     evaluate==0.4.3 \
#     fasttext==0.9.3 \
#     scikit-learn==1.6.1 \
#     scikit-image==0.25.2 \
#     gradio==5.23.1 \
#     numba==0.61.2 \
#     pyrsmi==0.2.0 \
#     pysqlite3==0.5.4 \
#     sentence-transformers==3.4.1 \
#     tensorboardX==2.6.2.2 \
#     torch-tb-profiler==0.4.3 \
#     tornado==6.4.2 \
#     tqdm-multiprocess==0.0.11 \
#     zstandard==0.23.0

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install omegaconf==2.4.0.dev3

# RUN $WITH_CONDA; set -eux ; \
#   git clone https://github.com/huggingface/lighteval /opt/mybuild ; \
#   cd /opt/mybuild ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip wheel --no-deps -e . -w /opt/wheels ; \
#   cd / ; rm -rf /opt/mybuild

# RUN $WITH_CONDA; set -eux ; \
#   CC=gcc-12 \
#   CXX=g++-12 \
#   pip install /opt/wheels/lighteval*.whl ; true

# # Gensim will require https://github.com/piskvorky/gensim/pull/3615 being merged
# # Without that it demotes numpy.
# # RUN $WITH_CONDA; set -eux ; \
# #   git clone https://github.com/piskvorky/gensim /opt/mybuild ; \
# #   cd /opt/mybuild ; \
# #   CC=gcc-12 \
# #   CXX=g++-12 \
# #   pip wheel --no-deps -e . -w /opt/wheels ; \
# #   cd / ; rm -rf /opt/mybuild

# # RUN $WITH_CONDA; set -eux ; \
# #   CC=gcc-12 \
# #   CXX=g++-12 \
# #   pip install /opt/wheels/gensim*.whl
# ENV CONDA_DEFAULT_ENV=pytorch
# ENV CONDA_SHLVL=1
# ENV CONDA_EXE="/opt/miniconda3/bin/conda"
# ENV CONDA_PREFIX="/opt/miniconda3/envs/$CONDA_DEFAULT_ENV"
# ENV _CE_M=''
# ENV CONDA_PYTHON_EXE="/opt/miniconda3/bin/python"
# ENV _CE_CONDA=''
# ENV CONDA_PROMPT_MODIFIER="($CONDA_DEFAULT_ENV)"
# ENV PATH="/opt/miniconda3/envs/$CONDA_DEFAULT_ENV/bin:/opt/miniconda3/condabin:$PATH"

# # Disable the WITH_CONDA helper
# ENV WITH_CONDA=true

# RUN set -eux ; \
#     echo '#!/bin/bash' > /entry.sh ; \
#     echo 'PATH='"$PATH"' exec "$@"' >> /entry.sh ; \
#     chmod +x /entry.sh

# ENTRYPOINT [ "/entry.sh" ]
# CMD [ "/bin/bash" ]